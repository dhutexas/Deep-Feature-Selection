{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#User-Guide-on-nonlinear-example\" data-toc-modified-id=\"User-Guide-on-nonlinear-example-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>User Guide on nonlinear example</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data Preparation</a></span></li><li><span><a href=\"#DFS-with-fixed-hyper-parameters\" data-toc-modified-id=\"DFS-with-fixed-hyper-parameters-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>DFS with fixed hyper-parameters</a></span></li><li><span><a href=\"#Selection-of-$s$\" data-toc-modified-id=\"Selection-of-$s$-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Selection of $s$</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feature Selection\n",
    "In this notebook, we will demonstrate how to implement our method on the nonlinear simulation examples from our paper.\n",
    "## User Guide on nonlinear example\n",
    "In this example, a high dimensional dataset with 500 covariates and 300 observations is generated using the following equation\n",
    "\n",
    "\\begin{equation}\n",
    "    y=\\begin{cases}\n",
    "        1, & e^{x_1} + x_2^2 + 5\\sin(x_3 x_4) - 3 > 0\\\\\n",
    "        0, & \\text{otherwise,}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "i.e. among 500 covariates, only the first 4 variables actually contributed to the response. Our task is to correctly select the important variables. Please see section 5.2 of the paper for detailed generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "from time import clock\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad\n",
    "from torch.nn.parameter import Parameter\n",
    "from utils import data_load_n, data_load_l, measure, accuracy\n",
    "from models import Net_nonlinear, Net_linear\n",
    "from dfs import DFS_epoch, training_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "We will load our data in the following chunk. The data, both covariates and response, need to be load as `pytorch` `Tensor` objects to be fed into the DFS algorithm. The function `data_load_n` will read in dataset and split it into training and test set so that both sets have same number of positive and negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The covariates is of type: <class 'torch.Tensor'>\n",
      "The response is of type: <class 'torch.Tensor'>\n",
      "\n",
      "The dimension of training set: torch.Size([300, 500])\n",
      "    The number of positive sample: 150\n",
      "    The number of negative sample: 150\n",
      "\n",
      "The dimension of test set: torch.Size([300, 500])\n",
      "    The number of positive sample: 150\n",
      "    The number of negative sample: 150\n"
     ]
    }
   ],
   "source": [
    "# load and prepare datasets\n",
    "dirc = \"../../data/nonlinear/p_500_N_600_s_4/\"\n",
    "k = 0 # dataset number from 0 to 9\n",
    "X, Y, X_test, Y_test = data_load_n(k, directory=dirc)\n",
    "N, p = X.shape\n",
    "print(\"The covariates is of type:\", type(X))\n",
    "print(\"The response is of type:\", type(Y))\n",
    "print()\n",
    "print(\"The dimension of training set:\", X.shape)\n",
    "print(\"    The number of positive sample:\", len(np.where(Y==1)[0]))\n",
    "print(\"    The number of negative sample:\", len(np.where(Y==0)[0]))\n",
    "print()\n",
    "print(\"The dimension of test set:\", X.shape)\n",
    "print(\"    The number of positive sample:\", len(np.where(Y_test==1)[0]))\n",
    "print(\"    The number of negative sample:\", len(np.where(Y_test==0)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFS with fixed hyper-parameters\n",
    "In this section, we demonstrate how to run DFS with one given set of hyper-parameters. The hyper-parameters includes:\n",
    "* `s`, the number of variables to be selected;\n",
    "* `c`, the tunning parameters to control the magnitude of $\\lambda_1$ and $\\lambda_2$;\n",
    "* `epochs`, the number of DFS iterations to be run;\n",
    "* `n_hidden1` & `n_hidden2`, the number of neurons in the fully connect neural networks;\n",
    "* `learning_rate`, the learning rate for optimizer;\n",
    "* `Ts` & `step`, the parameters to control the optimization on given support\n",
    "\n",
    "Among the above hyper-parameters, `s` is the most important parameters, and the selection of $s$ will be demonstrated in next sections. `c` can be selection through a sequence of candidates that returns the smallest loss function. Others mostly are meant to help the convergence of the optimization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyndows\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in 2 epochs, and took 1.4149964000000015 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wyndows\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:59: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# specify hyper-paramters\n",
    "s = 4\n",
    "c = 1\n",
    "epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 10\n",
    "learning_rate = 0.05\n",
    "Ts = 25 # To avoid long time waiting, this parameter has been shorten\n",
    "step = 5\n",
    "\n",
    "\n",
    "# Define Model\n",
    "torch.manual_seed(1) # set seed\n",
    "# Define a model with pre-specified structure and hyper parameters\n",
    "model = Net_nonlinear(n_feature=p, n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_output=2)\n",
    "# Define another model to save the current best model based on loss function value\n",
    "# The purpose is to prevent divergence of the training due to large learning rate or other reason\n",
    "best_model = Net_nonlinear(n_feature=p, n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_output=2)\n",
    "\n",
    "\n",
    "# Define optimizers for the optimization with given support\n",
    "# optimizer to separately optimize the hidden layers and selection layers\n",
    "# the selection layer will be optimized on given support only.\n",
    "# the optimzation of hidden layers and selection layer will take turn in iterations\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=learning_rate, weight_decay=0.0025*c)\n",
    "optimizer0 = torch.optim.Adam(model.hidden0.parameters(), lr=learning_rate, weight_decay=0.0005*c)\n",
    "\n",
    "\n",
    "# Define loss function\n",
    "lf = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Allocated some objects to keep track of changes over iterations\n",
    "hist = []\n",
    "SUPP = []\n",
    "LOSSES = []\n",
    "supp_x = list(range(p)) # initial support\n",
    "SUPP.append(supp_x)\n",
    "\n",
    "\n",
    "### DFS algorithm\n",
    "start = clock()\n",
    "for i in range(epochs):\n",
    "    # One DFS epoch\n",
    "    model, supp_x, LOSS = DFS_epoch(model, s, supp_x, X, Y, lf, optimizer0, optimizer, Ts, step)\n",
    "    LOSSES = LOSSES + LOSS\n",
    "    supp_x.sort()\n",
    "    # Save current loss function value and support\n",
    "    hist.append(lf(model(X), Y).data.numpy().tolist())\n",
    "    SUPP.append(supp_x)\n",
    "    # Prevent divergence of optimization over support, save the current best model\n",
    "    if hist[-1] == min(hist):\n",
    "        best_model.load_state_dict(model.state_dict())\n",
    "        best_supp = supp_x\n",
    "    # Early stop criteria\n",
    "    if len(SUPP[-1]) == len(SUPP[-2]) and (SUPP[-1] == SUPP[-2]).all():\n",
    "        break\n",
    "\n",
    "end = clock()\n",
    "print(\"Training finished in\" , len(SUPP)-1, \"epochs, and took\", end-start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following chunk, we will demonstrate the results from the DFS algorithm, in terms of selected support, training error and test error for __one step__ procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The support selected is: [0 1 2 3]\n",
      "The index of non-zero coefficents on selection layer: [0 1 2 3]\n",
      "The training error is: 0.0033333333333332993\n",
      "The test error is: 0.046666666666666634\n"
     ]
    }
   ],
   "source": [
    "### Metric calculation\n",
    "err_train_1 = 1-accuracy(best_model, X, Y)\n",
    "err_test_1 = 1-accuracy(best_model, X_test, Y_test)\n",
    "print(\"The support selected is:\", best_supp)\n",
    "print(\"The index of non-zero coefficents on selection layer:\", \n",
    "      np.where(best_model.hidden0.weight != 0)[0])\n",
    "print(\"The training error is:\", err_train_1)\n",
    "print(\"The test error is:\", err_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we have successfully selected the right support, i.e. the first 4 variables. (Note in `python` starting index is 0)\n",
    "\n",
    "In the following chunk, we will perform a two-step procedure to train the `best_model` on the given support.\n",
    "\n",
    "Two-step procedure is used for two reasons, to get better predictive performance and to get better estimation of $bic$ which is important in selection of optimal $s$.\n",
    "\n",
    "As we demonstrated on the above chunk, the selection layer of `best_model` has non-zero coefficients on given support. In the second step, we treat `best_model` as our initial model and update parameters only in hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of two step is: 100.0%\n",
      "The test accuracy of two step is: 96.0%\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer only update parameters in hidden layer.\n",
    "_optimizer = torch.optim.Adam(list(best_model.parameters())[1:], lr=0.01, weight_decay=0.0025)\n",
    "# Training\n",
    "for _ in range(100):\n",
    "    out = best_model(X)\n",
    "    loss = lf(out, Y)\n",
    "    _optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    _optimizer.step()\n",
    "\n",
    "### metric calculation\n",
    "acc_train = accuracy(best_model, X, Y)\n",
    "acc_test = accuracy(best_model, X_test, Y_test)\n",
    "print(\"The training accuracy of two step is: \", acc_train*100, \"%\", sep=\"\")\n",
    "print(\"The test accuracy of two step is: \", acc_test*100, \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result has shown that the predictive performance of our model is increased. \n",
    "\n",
    "All good results shown above is based on the correct given $s$. However, in reality, $s$ is unknown for most of the time. So the next thing would be finding the optimal $s$\n",
    "\n",
    "### Selection of $s$\n",
    "In this section, we demonstrate the procedure of selection of optimal $s$. We have wrapped up the training procedure above in a function `training_n`. For each given $s$, $bic$, defined as $-2 \\cdot \\log \\hat{L} + s \\cdot \\log n$, of the model will be automatically calculated by `training_n`, also the trained model with the given $s$ will also be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ss = list(range(2, 7)) # We shorten the candidates list in the notebooks\n",
    "BIC = [] # Store the bic for different s\n",
    "best_model = Net_nonlinear(n_feature=p, n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_output=2)\n",
    "for i, s in enumerate(Ss):\n",
    "    # Training dataset k with given s\n",
    "    model, supp, bic, _, [err_train, err_test] = training_n(X, Y, X_test, Y_test, c, s, \n",
    "                                                            epochs=10, Ts=25)\n",
    "    # Store bic values\n",
    "    BIC.append(bic)\n",
    "    # if current bic is the smallest, save the trained model, support and other metric\n",
    "    if bic == min(BIC):\n",
    "        best_model.load_state_dict(model.state_dict())\n",
    "        best_supp = supp\n",
    "        best_err_train, best_err_test = err_train, err_test # one step model training and testing error\n",
    "\n",
    "idx = np.argmin(BIC)\n",
    "best_s = Ss[idx]\n",
    "plt.plot(Ss, BIC)\n",
    "plt.axvline(x=best_s, ls='--', label=\"optimal s\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can tell $s=4$ is the optimal $s$, and the corresponding model is stored in `best_model` which is the same model showed in section 1.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
